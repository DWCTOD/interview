# 转行渣硕的算法路，记录走过的坑和一些笔经面经给转行算法的同学

https://www.nowcoder.com/discuss/295287

**我从今年7月15号投递出我的第一份简历，到9月28号结束秋招，两个多月的时间投递了差不多70家互联网/信息技术公司，面试了30多家，可以说一路都是在笔试和面试中成长的，老实说，有些面试官问的问题我至今还没搞懂……惭愧惭愧。PS：我学的大都是经典机器学习算法以及NLP领域的深度学习算法，投的岗位也都是与之相关的。**

我会挑选一些我认为印象深刻的面试经历以及笔试经历，记录下来，给转行或初学者做前车之鉴，大佬们看了也不要笑话我，恳请多多指正。

笔试或者面试过的公司大致如下：

1. 牛客sp：顺丰，ihandy，依图，快手，滴滴，拼多多，等等
2. 秋招牛客内推或直接网申：小米，腾讯，阿里，度小满，商汤，美团，华为，招行信用卡，拼多多，等等
3. 校招直接投简历：百度，比特大陆，oppo，远景，中信银行，中信信用卡，格力，58，平安健康险，没错又是拼多多，我连续投了三次，等等

**刚开始真的是初生牛犊不怕虎，我把很多了解很浅的东西写到了简历上去，导致我回答的也非常浅，常常被怼的生活不能自理，在此忠告各位，简历上的东西，一定要了解清楚再写上去，要多清楚呢？**

**1. 经典机器学习算法，至少要能亲手推到出来，如LR，SVM，朴素贝叶斯，xgboost，cbow等等，我提到的这几个算法可各个不简单，尤其是LR和SVM，真别看它们简单，也真的不要轻易说自己很懂，不然有可能会被问得很惨！**

**2. 推荐大家在大致了解某一个算法后，还是尽量去看看该算法的paper原文，这样能了解算法的细节，以免面试官问一些刁钻问题**

**3. 深度学习部分，比如语言模型，简单的，比如word2vec，fasttext，LSTM等要清楚的知道模型的细节，比如输入输出是什么，思想是什么，公式的推导等等；复杂些的模型，如BERT，ELMo，GPT等，需要知道网络的原理，网络提出的目的，每一层的作用是什么，长什么样子的，这样有什么好处等等，也是推荐尽量去看看原paper**

**4. 如果简历里面有比赛或者项目用到上述算法的，那就一定要弄到非常清楚**

**5. 然后就是编程，先建议把剑指offer刷完，刷两遍以上最好，写的时候如果半小时想不出思路，就直接看答案，等剑指offer刷完了，再去刷leetcode或者lintcode啥的，这样做的原因是首先剑指offer比较简单，然后呢国内面试官很可能出剑指offer上的原题（当然leetcode原题也会出现）**

**6. 然后就是基础数据结构知识，推荐看网易云课堂的《数据结构》这门课，由浙大老师免费倾情奉献，讲的简单易懂，灰常赞，不过一定要用自己用的语言去写一遍这些数据结构，有些面试官会钻牛角尖问你**

#### 我挑几个说说吧，写到面经（凉经）的公司为：顺丰，滴滴，快手，依图，腾讯，远景，百度，搜狗，oppo，58同城，华为

## **1. 顺丰sp和ihandy牛客专场：**

开篇就是吐槽，我为什么写这个？不是因为顺丰面试有多难，而是顺丰答应给我的二面，到现在都没给。。。从8月1号顺丰给了我人生中第一次公司面试到9月28号我结束秋招，在这期间顺丰不断推迟二面时间，现在又给我推到了10月中旬，不得不说，顺丰的hr还真是佛系呢。ihandy这货更狠，给我答应的一面到现在都没兑现，每次打电话过去问hr，都是同一个回答：马上帮您安排，然后我就继续傻傻的等一两个星期，循环往复。

#### 顺丰一面：

##  

> 1.自我介绍，为什么转行，你原来实验室干的什么？：因为喜欢算（qian）法（duo），原来实验室干的导航制导与控制；

> 2.介绍比赛，做了哪些数据的清洗，数据增强的处理？作了哪些特征？怎样提取特征的，为什么会想到这个特征呢？：balabala如实说，还说目前进入了复赛，正在复赛准备阶段XXXXX啥的；

> 3.我看你比赛用到了xgboost和lightGBM，那说下XGboost原理吧：额……不会；

> 4.那说下LightGBM吧：咳咳，也不会；

> 4.额那说下GBDT总行了吧：额……还是不会；

> 5.那你会啥？我：LR。（面试官快哭了T.T）；

> 6.那好吧那你说说LR吧：balabala；

> 7.你听过CATboost吗？我：没。（面试官再一次哭了）；

> 8.说说LSTM的原理：balabala还口述了输入门，更新门，输出门的公式；

> 9.你有什么想了解顺丰的吗？我：X$Y*&^%(&%@1！2￥……；

> 我知道我答的很菜，但我还是厚着脸皮问了面试官我的表现咋样，能否就我的面试情况和简历提点建议？后面每一次我视频面试我都会向面试官问这个问题，他们也都会热心的给我提出建议，帮我修改简历，收获很多。

> 结果：没想到一面给我过了，但是二面迟迟不到。

**2. 滴滴牛客sp专场（二面挂）:**

惭愧，当时在面试的时候还以为滴滴是小公司，问面试官问题的时候，我居然问了滴滴的业务存活情况……

#### 滴滴一面:

> 1.自我介绍，转行之类的问题；

> 2.了解那种算法挑一种介绍下：我说了LR，刚说到交叉熵这儿，面试官打断：那你说说LR为什么用交叉熵作为loss函数。我：因为lr从概率密度函数推导出来的对数极大似然函数就是交叉熵函数。面试官说：不全对，其实mse是万能的loss函数，每个模型都可以用mse作为loss函数的，那为什么lr不用mse呢？我：不几道。面试完了才想明白，mse的导数里面有sigmoid函数的导数，而交叉熵导数里面没有sigmoid函数的导数，sigmoid的导数的最大值为0.25，更新数据时太慢了；

> 3.说说XGB：在上次顺丰面完后，我仔细学习了一遍xgb，这一次大致回答上了面试官的问题，我说了GBDT，再从XGB是如何改进GBDT的角度引入了XGB的一些概念，比如预排序什么的，引入正则项和二阶泰勒展开什么的；

> 4.介绍比赛，介绍如何分工的，如何构建特征的，如何选择这些特征的；

> 5.说下常见的处理过拟合手段有哪些？我说了l1，l2，神经网络里的dropout，增加数据量等等，面试官问还有吗？我：不知道了。其实后来才知道bagging和boosting也是降低过拟合的手段，以前还以为仅仅是种特殊的模型。

> 同样向面试官问了我的表现情况以及如何改进，面试官也热心的提出了建议。

#### 滴滴二面:

> 1.自我介绍，大致介绍项目。

> 2.聊比赛，聊人生。。。。。大概聊了30多分钟。

> 3.问你会不会什么操作系统，数据库啥的，c++会不会。答：都不会

> 二面很自然的就挂了，从滴滴的面试可以看出，其实国内的很多公司都挺看中开发能力的，只会python和跑跑模型应该达不到绝大多数公司的要求。

**3.快手牛客sp专场（二面挂）**

#### 快手一面：

> 1.基础问题都是老生常谈，问题和回答略了

> 2.算法题：求最长回文子串，leetcode原题，动态规划求解最好，但我当时不会，用的是中心展开法，勉强做了出来。

#### 快手二面

> 1.上来一道leetcode上的hard算法题：求最小编辑距离。不会，直接gg

> 2.其他闲聊，聊人生

> 大概等了10多天，官网上给我挂了

**4.依图（一面挂）**

#### 依图

> 是我最惨的一次面试，面试官笑眯眯的，也没让我自我介绍，上来四到算法题，一道一道来的那种，题目都忘了，只记得每道都把我摁在地上摩擦，差不多情况就是这样：

> 面试官：出道算法题吧，第一道：XXXX。

> 我思索10分钟：不会；

> 面试官：那我们做第二道吧：XXXX。

> 我又思索10分钟：不会……；

> 面试官：那再来一道：XXXX。

> 我寻思我都这么惨了放过我让我走吧求你了，于是思索了两分钟说：还是不会……；

> 面试官：那再来一道：XXXX。

> 我：gun！

> 后来视频面试结束的时候，我专门去查了这几道题目，他们都有一个统一的解法，那就是动态规划，抱歉我之前真没听过动态规划啊啊啊啊啊，我从此下定决心，进行dp的专项练习。

**5.腾讯（一面挂，好后悔没有抓住唯一一次进鹅厂的机会）**

#### 腾讯

> 其实面试官问的问题都很简单，但是当时比赛刚做完，非常疲惫，不想学习，没有学习新的东西，也没复习旧的东西，就这样躺尸了两天，然后腾讯的技术面试官晚上打来电话面试：

> 1.自我介绍，介绍比赛

> 2.看你用到了朴素贝叶斯，说下原理吧。我心想这还不简单，刚要张嘴，才发现坏了，啥叫朴素贝叶斯来着？我给忘了！我就支支吾吾的说：用了贝叶斯公式，然后加上了观测独立假设，面试官无语……

> 3.说下xgb，lgb和gbdt吧。这个我会，由于前面问了很多了，不用复习也能张口就来。

> 4.我看你的另一个比赛用了bert和CRF，说说CRF的原理吧。我：……不会（后悔没看）

> 5.那说下bert的原理吧。我：……还是不会（好后悔啊，太懒了，还是没看）

> 后面balabala的问了一堆，我都回答上了，但是前面这几个没回答上的太伤了，一面挂

**6.远景（四面挂，boss面挂的，真是挂的莫名其妙……）**

#### 一面，二面，三面（都超级水）：

> 都是随便介绍项目，问一些基础的问题，没啥难的，印象深刻的是二面面试官问到最后突然让我用英文介绍下比赛里面是如何选择特征的，我用我的工地散装英语一顿乱说，结束时面试官说嗯很不错，我内心：靠，你压根就没听吧！

#### 四面（boss面）：

> 四面是boss面，现场面的，聊人生，跟我聊了一个半小时，全程也穿插问些问题，我都回答上了，跟boss聊得非常好，然后就给我莫名其妙的挂了……，我想原因应该是boss临走前给我说了一句：你需要多注重工程能力。他可能嫌我工程项目很少吧。

**7.百度（一面挂）**

#### 1.百度笔试：

> 百度的笔试就令人印象深刻：

> 选择题啥都考，很杂，操作系统，数据库，c++，python，机器学习，深度学习啥都考

> 两道问答题，其中有一问印象深刻：说说针对中文，BERT有什么可以改进的地方。我心想：你丫不就是想吹自己的ERNIE嘛，我就写了ERNIE针对BERT做出的改进，基于知识的mask训练方式，基于知识图谱的改进等等

> 一道设计题，让你设计一个系统：可以写出春联，必须满足他的要求，平仄音节都要对上，我直接BERT+CRF+GPT一顿乱写。

> 编程题：RGB括号，我猜应该是道dp题吧，链接：<https://www.nowcoder.com/discuss/254095>

> 想看的童鞋可以看一看，无视我的答案就好，我到现在都不知道我的答案对不对。

#### 2.百度一面：被疯狂摩擦，问的非常细：

> 1.红黑树的几个特点。只答上两个，其实我根本不会

> 2.python的装饰器@的用法。不会

> 3.编程，写一个函数，实现python的继承，数据的交换，类中的全局变量等等。写上了一半。

> 4.快排（不能用简单粗暴的那种，要空间复杂度最低的）和堆排序（必须用最小堆实现）。不是让你写代码，而是给你一个数组，直接让你用快排和堆排的思想直接一个元素一个元素的演示给他看，这个我答上了，幸好之前自己实现过弄懂了。

> 5.算法题dp两道：最长公共子串，最长公共子列，都是dp题，幸好专门看了九章算法，专项学习了dp，简单或者中等的dp题还是可以一战的，这两道也是lintcode上的原题，有兴趣的童鞋可以查查。

> 6.介绍xgb，我说到“xgb的预排序是相对于暴力求解的加速”这儿，面试官打断了我，反问我：那具体是为什么加速了呢？一个特征下的数据，没有预排序和预排序了，不都得遍历一遍才能求解出最优分裂点吗？

> 这个问题给我干蒙了，其实这个问题我之前思考过，但是太懒了，心里不断麻醉自己面试官不会问得这么细，就直接忽略了，没再去想。百度面试完以后我看了原论文的伪代码才明白为什么。所以再次建议尽量能读一读原paper。

> 7.介绍下xgb是如何调参的，哪一个先调，哪一个后调，为什么？哪几个单独调，哪几个放在一组调，为什么？哪些是处理过拟合的，哪些是增加模型复杂程度的，为什么？我寻思你十万个为什么呢？总之就是被为什么问的头昏脑涨，出了门我就知道肯定挂了。

**8.搜狗（面试流程结束）**

#### 1.搜狗一面（一个半小时摩擦系列）：

> 1.lr为什么用sigmoid函数作为概率函数。我：lr是基于伯努利分布为假设的，伯努利分布的指数形式就是sigmoid函数，而且sigmoid函数可以将数据压缩到0-1内，以便表示概率。

> 2.介绍下word2vec，说说word2vec和fasttext的区别。我：balabalabala，说的貌似还行，面试官点头

> 3.印象深刻的推导：

> 推导下word2vec里面的一个模型CBOW吧。后悔没看，哭了，我说不会。

> 那推导下SVM吧。这个我会，推出来了，但是到对偶条件这里，面试官问为什么能用对偶条件，我没答上来，还是太菜。

> 那再推下lr吧。这次顺利的推了出来，面试官问的问题也回答了上来。顺利通过了。

> 4.算法题：求最长回文子串，没错，和前面快手一面问的笔试题一样，答上了。

> 5.概率题，严格来说，这道题不是我遇见的，是我同学面搜狗的时候被问到的，我觉得很有意思，而且我们都不知道答案，请大佬解答：

```
一共54张扑克牌，我抽了几张牌（大于2张），有两种场景：
1.我说我有小王；
2.我说我有大王；
这两种情况，哪种有双王的概率更高？
```

这题我是一脸懵逼的，求各位大佬解答！

2.搜狗二面：

> 1.xgb的loss函数的推导（mse以及非mse形式），以及求解推导。

> 推出来了；

> 2.求最大连续子列和，要求时间空间复杂度最小。

> 很简单；

> 3.xgb是如何实现并行的。

> 保存预排序的block，用进程间的通信并行寻找最优分裂点。

> 4.lgb的直方图优化算法说说。

> 随便说了说，面试官也没深问。

> 5.讲比赛，讲项目。

> balabalabal总之二面持续了差不多一小时

#### 3.搜狗hr面：

> 没啥好讲的，聊人生，聊转行，hr说需要综合各地的信息来筛选，让我回去等消息。

**9.OPPO（offer）**

我整个秋招所经历的所有面试官里面，一共面了三个非常有水平的面试官（我个人觉得）：一个是远景的那个boss，微软亚研院呆了四年，百度呆了六年，google呆了六年。和我聊现在的行业形势以及各种模型的应用，很多问题都会直击要害，一语中的。和我的聊天中看出了我工程能力不足，跟我聊了一个半小时，为我未来提出了一些建议和规划，我很感谢那位大叔；第二个是百度的一面面试官，他好像就是住在我肚子里的蛔虫一样，总能在我的回答中揪出我不会的致命知识点，给我痛击，真的是怕啥他考啥，他的基础非常扎实，而且反应和判断非常迅速；第三个就是这个oppo的一面面试官，根本不问固定知识点，就问一些模型、手段、措施背后的本质并且举例说明，在你运用的实际场景中有没有见过。

#### 1.OPPO一面：

> 刚开始都没让我自我介绍，直接让我说比赛。我：balabala，我介绍到CRF的时候，面试官打断我说：“你说CRF说了一大堆，那他它本质是个啥东西，我不要听那些定义，你给我说本质”。我：……支支吾吾……，说它应该是个函数，balabalaba一顿编。

> 然后他也没说对错，继续问：说下attention吧，我：又是一顿balabala，讲到注意力那儿的时候他问：你能举个case吗，用了attention和没用attention时候的对应的隐状态在哪些地方有区别你有去观察过吗？我：又是一顿瞎bala，他又没说对还是错。

> 又问我看你这里用到bilstm它和lstm的区别在哪？举例说明，用了和没用的效果。我心想：哎呦终于有个会的了，结果回答完他还是那副样子，又是啥也没说，我心想对还是错你倒是给个准信啊。

> 又问到了ELMo，让我说明ELMo是如何做到动态词向量的。我：把每个词输入模型，得到的隐状态相加就能得到不同的词向量；

> 面试官：那说下ELMo的缺点。我说：第一就是多层bilstm天生的缺点：“自己看到自己”的现象，然后举了个例子，balabala……。第二就是无法并行训练，以上两个毛病都可以用bert去改进它；

> 他又问其实我们可以用加入位置嵌入的方式来改进这个无法并行的问题那为什么非得用bert呢？我一想确实facebook貌似在之前就提出了位置嵌入+textcnn的方式来并行训练。完了，给自己挖坑了。于是乎我就扯了一堆bert里面self-attention的优点，哈哈哈我真是机智。

> 然后他依旧啥也没说，又让我介绍bert，并且问了multi-head的好处，又问我它的实际物理意义是什么？为什么能这么想？举个case说明下。我用尽了我毕生瞎编的本事，凭借着我自己的一点理解硬是说了10分钟，然后结束了是对是错他还是啥也没说……………………

> 又让我写LSTM的公式，勉强写上了

> 又问了我一个实际场景问题：用一个模型去分类一堆数据，在training阶段就无法收敛，反复震荡，有可能是什么原因，你有没有在实际场景中遇见过？

> 我：可能数据是标注错误的或者是随机数据，面试官补刀：假设数据没问题，那是什么原因？

> 我：那就是模型无法拟合这个数据或者不适合做这类数据的分类，面试官再补刀：假设模型也没问题，足够复杂。

> 我：那有可能是优化过程陷入了局部最优，而且一直无法跳出，面试官再次补刀：假如优化过程没问题。

> 我：那就是正负样本极其不均，网络没法学习到东西？面试官：我没说一定是神经网络模型，而且那再假如样本正负分布是均匀的……

> 我：……那我真没遇见过这样的……

> 面试官当时貌似不太满意，跟我聊完居然把我的简历给对折了起来！我第一次见这种场面……，心想：哎呦我去凉了，可能一出门面试官就会把我的简历扔垃圾桶里了吧……。面试官让我回去等，晚上如果收到消息就是过了，没收到就是挂了。晚上感觉想哭，毕竟OPPO是我蛮喜欢的一个公司，结果快睡着了突然来了一个短信提醒，说我OPPO面试过了……，得，这下倒好，睡不着了……

#### 2.OPPO二面（主管面）：

> 1.聊项目比赛，一路下来没问啥知识点，没啥大问题

> 2.画出ESIM这个模型的结构，并作介绍

> 3.面试官看我航天二院的项目跟导弹拦截有关系，是用GRNN预报弹道的，就让我介绍下GRNN的网络结构以及原理，还问预报精度怎么样。我说这个题目现在是我的毕设，还没做完呢……

> 面试官：哦……那你给我说说你要拦截的这个HTV-2是个啥？

> 我说：是一种美国的临近空间高超声速飞行器，可用于导弹上，对我国国防安全造成威胁，balabalabala……

> 面试官好像突然来了兴趣，一直问我导弹的事，跟个好奇宝宝一样：这个HTV-2很厉害吗？

> 我：点头，嗯嗯嗯

> 面试官：这个HTV-2有啥特点？你们用经典的方法一般是咋拦截的？balabala……

> 我：额……这些都是保密的……

> 面试官：哦，那没事了。

> 4.聊到后面问我有没有了解过一些其他的搜索排序算法，比如list-wise的，pair-wise的，然后给你一堆非常大的大数据，如何实现全数据的搜索排序，我凭借我的理解大致回答了一些，面试官说还不错，让我等下一面

#### 3.hr面：

> 我拿起我的oppo find x给hr一顿瞎BB，意向书成功到手，虽然是白菜价，但是OPPO是我很想去的一家公司，尤其是近几年开始搞些奇奇怪怪的手机出来以后越想去了- . -。

> 我原以为一面二面回答的不太好的情况下OPPO也愿意要我，而且hr说今年OPPO机器学习投递的简历，光筛选后的985计算机科班硕士的就多的吓人，所以我感觉OPPO今年应该在机器学习这个岗位上招人需求有很多。没想到签约会时候问hr才得知整个哈尔滨加吉林地区，机器学习的offer只有两个……，瞬间脊背发凉……

**10.58同城（口头意向，拒了）**

其实能面试58我是非常意外的，因为58的笔试编程题我一道都没做出来，选择题差不多一半都是瞎猜的，甚至面试的时候，面试官还把我做错的选择题拿出来又问了我一遍，并且我还是答错了……囧，而且三个面试官都问了我：为什么编程题一道都没做？………好尴尬，太奇怪了！？58怎么会给我面试呢？不过面试时我表现的还不错，最后也拿到了口头意向，但已经签了OPPO就给拒了。

#### 1.58一面：

> 1.还是各种介绍，自我介绍，比赛，项目，为什么转行啥的。

> 2.我看你用了ESIM这个模型，把模型结构画一下，并且告诉我为什么有用。很简单。

> 3.算法题：一个数组中和为k的所有二元组，要求时间复杂度为O(n)。这个也很简单。

> 4.介绍下BERT以及CRF。老生常谈了，他也没深问。

> 5.算法题：最小编辑距离，没错又一次被问到了，dp常规思路，只不过需要多考虑边界条件。完美解决。

> 6.算法题：一块钱一瓶水，三个瓶盖能换一瓶水，问20块最多能买多少瓶水？（用编程方法解决。）面试官午饭没吃，饿的等不及了，我刚想了一分钟还没写出来，面试官说一面就到这儿吧，我以为他要把我挂了，赶快急急地说了思路，面试官说没事你一面过了，走去吃饭吧，噗.......

> **2.58二面：**

> 二面大多数时候都是我在问面试官，一时间搞不清楚谁才是真面试官……问了些58的业务，以及业务中需要的模型，算法等等的。聊得很开心，当然也有些坑，面试官会穿插着问些技术问题，比如在谈到58的软件内搜索业务的时候，面试官问如何在少量数据的情况下对用户的输入进行快速的意图识别。我说了几条：可以用信息熵来确定用户输入主体，用聚类来做些简单的意图识别等等。

> **3.58hr面：**

> 一个很漂亮的大姐，很亲和，又是聊人生，结束后告诉我回去等通知。

**11.华为（offer，拒了）**

我申请的是华为消费者bg软件部的人工智能工程师，自然语言处理/语音处理方向。我听说今年很难进华为，想进消费者更是难上加难，但是我仍然没感觉到有多难进……可能华为比较看重课业成绩和学历吧，因为我感觉我只有这个优势……

#### 1.华为一面：

> 上来两到算法题，不过都是很简单的leetcode原题，题目我给忘了，但是都答上了。但是我感觉面试难度看脸，有同学就被甩了两道dp题没答上来一面就挂了。

> 问的问题都很基础，知识点都是前面的那些，没有什么印象深刻的问题。

#### 2.华为二面

> 算法题：求一个数组中和为k的最长连续数组，暴力法解决的，面试官说没有复杂度要求。

> 问了槽位的概念，这个我之前真没听过，哎，还是太菜了。

> 问了些其他的基础问题

#### 3.华为三面

> 聊人生，聊规划，圆满结束，offer到手，签约会的时候，hr说给我安排到北京了，我不太想去北京，而且薪资也不高（我听到的消费者的同学都一个均价，什么硬件研究院、智能车、无线的均价都比消费者高），而且最重要的是，他把我安排到了消费者软件部下的智慧城市这个三级部门，大概率是语音方向的，我不是特别喜欢，就给拒了。

> 感恩还愿，回馈牛客！

> **以上就是一部分苦逼的面试生涯，祝大家都能找到心仪的offer，我这么菜的都找到了，大家加油！**